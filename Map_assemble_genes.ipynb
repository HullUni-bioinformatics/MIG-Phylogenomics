{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get genes, CDSs and protein for samples without assemblies\n",
    "## 2.1. Map and assemble genes BWA \n",
    "Map the read sub sample from the `mitogenomes` directory to the baits to get a \"genes\" fasta for each sample. Only retain the backbone file of iteration1 and delete everything else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Determine which reference sample to use for each sample, and what missmatch percentage\n",
    "javanica and incognita are expected to be almost identical to their reference genomes and arenaria slightly divergent. It is important to use low missmatch factor to avoid spurious mapping, but also not too low, so that homologous but divergent reads can map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smpl2ref = {   #ref      # max mismatch\n",
    "    'MjavVW5':['MjavVW4', 2],\n",
    "    'MareL28':['MareHarA',5],\n",
    "    'MincA14':['MincW1',  2],\n",
    "    'MincL17':['MjavVW4', 2],\n",
    "    'MincL27':['MincW1',  2],\n",
    "    'MincL15':['MjavVW4', 2],\n",
    "    'MjavL57':['MjavVW4', 2],\n",
    "    'MincVW6':['MincW1',  2],\n",
    "    'MincL9' :['MincW1',  2],\n",
    "    'Minc557R':['MincW1',  2],\n",
    "    'MincL19':['MincW1',  2],\n",
    "    'MareL32':['MareHarA',5],\n",
    "    'MincHarC':['MincW1',  2],\n",
    "}\n",
    "\n",
    "raw_data = {\n",
    "    # smpl_id: [sra_accession, read1_fname, read2_fname]\n",
    "} # to do\n",
    "\n",
    "misc.makedir('raw_reads')\n",
    "\n",
    "# for smpl_id in raw_data:\n",
    "#     get sra accession\n",
    "#     dump fastq files to raw_reads\n",
    "#     rename read1_fname to smpl_id_1.fastq.gz\n",
    "#     rename read2_fname to smpl_id_2.fastq.qz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Download the read data from SRA and quality trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import misc, re, os\n",
    "\n",
    "\n",
    "for smpl in smpl2ref:\n",
    "    \n",
    "    raw1 = \"raw_reads/%s_1.fastq.gz\"%smpl\n",
    "    raw2 = \"raw_reads/%s_2.fastq.gz\"%smpl\n",
    "    \n",
    "    pairedtrimmed1 = raw1.replace('.fastq.gz','_trimmomatic.fastq.gz')\n",
    "    pairedtrimmed2 = raw2.replace('.fastq.gz','_trimmomatic.fastq.gz')\n",
    "    \n",
    "    if os.path.exists(pairedtrimmed1):\n",
    "        continue\n",
    "    \n",
    "    unpairedtrimmed1 = raw1.replace('.fastq.gz','_trimmomatic_up.fastq.gz')\n",
    "    unpairedtrimmed2 = raw2.replace('.fastq.gz','_trimmomatic_up.fastq.gz')\n",
    "\n",
    "\n",
    "    adapters = \"../mitogenomes/adapters.fasta\"\n",
    "    a = \"java -jar /usr/bin/trimmomatic.jar PE -phred33 %s %s %s %s %s %s \"\n",
    "    b = \"ILLUMINACLIP:%s:2:30:10 LEADING:30 TRAILING:30 SLIDINGWINDOW:4:15 MINLEN:80\"\n",
    "    c = a+b\n",
    "    cline = c%(raw1,\n",
    "                 raw2,\n",
    "                 pairedtrimmed1,\n",
    "                 unpairedtrimmed1,\n",
    "                 pairedtrimmed2,\n",
    "                 unpairedtrimmed2,\n",
    "                 adapters)\n",
    "\n",
    "    #print \"Trimming the file %s\"%raw1\n",
    "    #print \"Output written to %s\"%pairedtrimmed1\n",
    "    #print \"using command\\n%s\"%cline\n",
    "\n",
    "    err, out = misc.execute_cline(cline)\n",
    "    \n",
    "    #print out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Run BWA\n",
    "#### 2.1.3.1 Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# File and command line templates\n",
    "# -------------------------------\n",
    "\n",
    "# The paths assume we moved to a subdirectory of cwd\n",
    "readpool = \"raw_reads/%s_%i_trimmomatic.fastq.gz\"\n",
    "ref = \"../all_gene_ref_reviewed/%s_ref.nt.fasta\"\n",
    "bwadir = \"./%s_bwa/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# command line templates\n",
    "cdcline = \"cd %s && %s && cd ..\" #%(bwadir, cline)\n",
    "indexcline = \"bwa index %s\"   #%(ref)\n",
    "aligncline = \"bwa aln -n %i %s %s > %s%i.sai\" #%(missmatch, ref, readpool, smpl,read)\n",
    "sampecline = \"bwa sampe %s %s1.sai %s2.sai %s %s > %s.sam\" #%(ref, smpl, smpl, readpool1, readpool2, smpl)\n",
    "sortcline  = \"samtools sort -o %s.bam -T %s -@ 1 -O bam %s.sam\" #%(smpl,smpl,smpl) \n",
    "idxbamcline= \"samtools index %s.bam\"#%smpl\n",
    "fbayescline= \"freebayes -f %s -p 1 --report-monomorphic %s.bam > %s.vcf\" #%(ref, smpl, smpl)\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# A function for a single run that happens in a new subdirectory\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "def index_bwa_refs(smpl2ref):\n",
    "    \n",
    "    import misc\n",
    "    \n",
    "    ref_samples = set([i[1][0] for i in smpl2ref.items()])\n",
    "    \n",
    "    for refsmpl in ref_samples:\n",
    "        \n",
    "        smpl_ref = ref[1:]%refsmpl\n",
    "        \n",
    "        misc.printoe(\n",
    "            misc.execute_cline(indexcline%smpl_ref)\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "def run_map_assembly(smpl, smpl2ref, vcf=True, fasta=True):\n",
    "    \n",
    "    import misc\n",
    "    import os\n",
    "    import sys\n",
    "    from warnings import warn\n",
    "    \n",
    "    \"\"\"\n",
    "    This is a very context dependant function to run mitobim\n",
    "    on a single sample\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # A subdirecotry of cwd in which mitobim will run for smpl\n",
    "    outdir = bwadir%smpl\n",
    "    \n",
    "    misc.makedir(outdir)\n",
    "    \n",
    "    # specific input and ouput fpaths for smpl\n",
    "    smpl_readpool_1 = readpool%(smpl,1)\n",
    "    smpl_readpool_2 = readpool%(smpl,2)\n",
    "    smpl_ref = ref%smpl2ref[smpl][0]\n",
    "    missmatch = smpl2ref[smpl][1]\n",
    "    \n",
    "    # Check the inputs exists and outputs don't\n",
    "    readpool1_exists = os.path.exists(smpl_readpool_1)\n",
    "    readpool2_exists = os.path.exists(smpl_readpool_2)\n",
    "    ref_exists = os.path.exists(outdir+smpl_ref)\n",
    "    output_exists = os.path.exists(outdir+'.gz')\n",
    "    \n",
    "    if output_exists:\n",
    "        warn('skipping %s, output exists'%smpl)\n",
    "\n",
    "        \n",
    "    elif not readpool1_exists or not readpool2_exists:\n",
    "        warn('skipping %s, cannot access readpool'%smpl)\n",
    "\n",
    "        \n",
    "    elif not ref_exists:\n",
    "        warn('skipping %s, cannot access ref'%smpl)\n",
    "        \n",
    "    else:\n",
    "        # Make sample specific clines\n",
    "        clines = [\n",
    "            # bwa aln\n",
    "            aligncline%(missmatch, smpl_ref, smpl_readpool_1, smpl,1),\n",
    "            aligncline%(missmatch, smpl_ref, smpl_readpool_2, smpl,2),\n",
    "            # bwa sampe\n",
    "            sampecline%(smpl_ref, smpl, smpl, smpl_readpool_1, smpl_readpool_2, smpl),\n",
    "            # sort sam by start\n",
    "            sortcline%(smpl,smpl,smpl),\n",
    "            # clean\n",
    "            'rm *.*ai','rm *.sam',\n",
    "        ]\n",
    "        \n",
    "        if vcf:\n",
    "            # index bam file\n",
    "            clines.append(idxbamcline%smpl)\n",
    "            # make vcf file\n",
    "            clines.append(fbayescline%(smpl_ref, smpl, smpl))\n",
    "        \n",
    "        # run the workflow\n",
    "        for cline in clines:\n",
    "            print \"executing\", cdcline%(outdir, cline)\n",
    "            sys.stdout.flush()\n",
    "            misc.printoe(\n",
    "                misc.execute_cline(cdcline%(outdir, cline))\n",
    "            )\n",
    "        \n",
    "        # make genes fasta\n",
    "        if fasta:\n",
    "            vcf2con(\"%s.vcf\"%smpl, outdir, smpl)\n",
    "            \n",
    "        # delete bam\n",
    "        # I am keeping it for now\n",
    "        #misc.printoe(\n",
    "        #    misc.execute_cline(cdcline%'rm *.bam')\n",
    "        #)\n",
    "        \n",
    "        # delete vcf\n",
    "        misc.printoe(\n",
    "            misc.execute_cline(cdcline%(outdir, 'rm *.vcf'))\n",
    "        )\n",
    "        \n",
    "        # compress the output dir\n",
    "        misc.printoe(\n",
    "            misc.compressgz(outdir)\n",
    "        )\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# A function to convert vcf to assembly\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "def vcf2con(vcfin, workdir, smpl):\n",
    "    \n",
    "    \"\"\"This will use christophs vcf_2_consensus\n",
    "    to take a vcf file and write separate fasta\n",
    "    entries in one file for each assembled gene\"\"\"\n",
    "    \n",
    "    from Bio import SeqIO\n",
    "    import misc\n",
    "    import os\n",
    "    \n",
    "    # output fasta files with assembled genes\n",
    "    out = open(\"%s/%s.nt.fasta\"%(workdir,smpl),'wt')\n",
    "    \n",
    "    with open(workdir+vcfin, 'r') as lines:\n",
    "        \n",
    "        locus_vcf_lines = []\n",
    "        current_locus = ''\n",
    "        header = []\n",
    "        \n",
    "        for line in lines:\n",
    "            \n",
    "            # skip header lines in vcf\n",
    "            if line.startswith('#'):\n",
    "                header.append(line)\n",
    "                continue\n",
    "            \n",
    "            # The bait name (gene in the reference file)\n",
    "            line_locus = line.split()[0]\n",
    "            \n",
    "            # Is it is the first vcf line, get he gene\n",
    "            # name and the line\n",
    "            if current_locus == '':\n",
    "                current_locus = line_locus\n",
    "                locus_vcf_lines.append(line)\n",
    "            \n",
    "            # If it is not the first line, and the gene\n",
    "            # is the same as before, add the line\n",
    "            elif line_locus == current_locus:\n",
    "                locus_vcf_lines.append(line)\n",
    "                \n",
    "            # If this line referes to a new gene,\n",
    "            # write a vcf file containing the lines\n",
    "            # of the previous gene, and write them as \n",
    "            # a fasta assembly, then start a list for\n",
    "            # for the new gene\n",
    "            else:\n",
    "                \n",
    "                # a vcf file with lines belonging\n",
    "                # only to one genes\n",
    "                tmp = open(workdir+'tmp.vcf','wt')\n",
    "                for l in header+locus_vcf_lines:\n",
    "                    tmp.write(l)\n",
    "                tmp.close()\n",
    "                \n",
    "                # Write a fasta file with an assembly of\n",
    "                # the single gene\n",
    "                cdcln = \"cd %s && %s && cd ..\" #%(workdir, cline)\n",
    "                executable = \"python vcf_2_consensus.py\"\n",
    "                convcln = \"%s -f -o %s tmp.vcf\"%(executable,smpl)\n",
    "                cline = cdcln%(workdir, convcln)\n",
    "                #misc.printoe(\n",
    "                misc.execute_cline(cline)\n",
    "                #)\n",
    "                \n",
    "                # Add the fasta assembly to a fasta file\n",
    "                # with all the assembled gened\n",
    "                record = SeqIO.read(workdir+smpl+'.fas','fasta')\n",
    "                record.id = current_locus\n",
    "                record.description = ''\n",
    "                out.write(record.format('fasta'))\n",
    "                os.remove(workdir+smpl+'.fas')\n",
    "                os.remove(workdir+'tmp.vcf')\n",
    "                \n",
    "                # Reset the list and the gene name\n",
    "                # for the following gene in the \n",
    "                # original vcf file\n",
    "                current_locus = line_locus\n",
    "                locus_vcf_lines = [line]\n",
    "                \n",
    "    out.close()                \n",
    "                            \n",
    "\n",
    "#--------------------------------------------------------------\n",
    "# A function to run several gene assembly processes in parallel\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "def run_parallel_map_assmbly(smpl2ref):\n",
    "    \n",
    "    \"\"\" This will run run_map_assembly \n",
    "    for all the samples in parallel\"\"\"\n",
    "    \n",
    "    import threading\n",
    "    import os\n",
    "    \n",
    "    index_bwa_refs(smpl2ref)\n",
    "    \n",
    "    class MyThread(threading.Thread):\n",
    "        def __init__(self, smpl, smpldict):\n",
    "            threading.Thread.__init__(self)\n",
    "            self.smpl = smpl\n",
    "            self.smpl2ref = smpldict\n",
    "\n",
    "        def run(self):\n",
    "            run_map_assembly(self.smpl, self.smpl2ref)\n",
    "            \n",
    "    threads = [MyThread(smpl, smpl2ref) for smpl in smpl2ref.keys()]\n",
    "\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "        \n",
    "    from glob import glob\n",
    "    \n",
    "    for f in glob('./gene_ref_reviewed/*_ref.nt.fasta.*'):\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3.2 Make gene files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_parallel_map_assmbly(smpl2ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Get CDSs and proteins from the map-assembled genes, using  exonerate, for samples without a genome assembly\n",
    "Search a CDS in each assembled gene using a Protein as query.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_a_single_record(record):\n",
    "    \n",
    "    output = {}\n",
    "    \n",
    "    def parse_line_element(ind, parter, element_name):\n",
    "        elementline = record[ind]\n",
    "        try:\n",
    "            output[element_name] = elementline.rstrip().split(parter)[1]\n",
    "            if ' [revcomp]' in elementline:\n",
    "                output[element_name] = output[element_name].replace(' [revcomp]','')\n",
    "            elif ' -> ' in output[element_name] and \\\n",
    "                 element_name == 'Target_start':\n",
    "                output[element_name] = output[element_name].split(' -> ')[0]\n",
    "            elif ' -> ' in output[element_name] and \\\n",
    "                 element_name == 'Target_end':\n",
    "                output[element_name] = output[element_name].split(' -> ')[1]\n",
    "            try:\n",
    "                output[element_name] = int(output[element_name])\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            raise RuntimeError(\"%s not found\"%parter)\n",
    "\n",
    "            \n",
    "    line_elements = [[2, 'Query: ', 'Query'],\n",
    "                     [3, 'Target: ', 'Target'],\n",
    "                     [5, 'Raw score: ', 'Score'],\n",
    "                     [7, 'Target range: ', 'Target_start'],\n",
    "                     [7, 'Target range: ', 'Target_end']]\n",
    "    \n",
    "    \n",
    "    for ind, parter, element_name in line_elements:\n",
    "        parse_line_element(ind, parter, element_name)\n",
    "        \n",
    "    def parse_block_element(init, halt, element_name):\n",
    "        element = \"\"\n",
    "        get = False\n",
    "        for line in record:\n",
    "            if init in line:\n",
    "                get = True\n",
    "            elif halt in line:\n",
    "                get = False\n",
    "            elif get:\n",
    "                element += line\n",
    "        output[element_name] = element\n",
    "        \n",
    "    block_elements = [['STARTGENE','ENDGENE','Gene'],\n",
    "                      ['STARTCDS','ENDCDS','CDS'],\n",
    "                      ['--- START OF GFF DUMP ---',\n",
    "                       '--- END OF GFF DUMP ---',\n",
    "                       'GFF']\n",
    "                     ]\n",
    "    for init, halt, element_name in block_elements:\n",
    "        parse_block_element(init, halt, element_name)\n",
    "        \n",
    "    return output\n",
    "\n",
    "def iter_records(fpath):\n",
    "    with open(fpath,'r') as lines:\n",
    "        record = []\n",
    "        get = False\n",
    "        for line in lines:\n",
    "            if 'C4 Alignment:' in line:\n",
    "                get = True\n",
    "            if get and 'C4 Alignment:' in line:\n",
    "                if len(record) > 0:\n",
    "                    yield record\n",
    "                    record = [line]\n",
    "                else:\n",
    "                    record = [line]\n",
    "            elif get:\n",
    "                record.append(line)\n",
    "        yield record\n",
    "\n",
    "def single_gene_exonerate(prot, gene, chain = ''):\n",
    "    \n",
    "    import misc, os\n",
    "    from StringIO import StringIO\n",
    "    from Bio import SeqIO\n",
    "    \n",
    "    ## exonerate cline\n",
    "    # query and target\n",
    "    a = \"exonerate -q %s -t %s \"%(prot, gene)\n",
    "    # search CDS in DNA and get only the best result\n",
    "    b = \"-m protein2genome -n 1 \"\n",
    "    # format the output into gene and CDS fasta (exonerate roll your own syntax\n",
    "    # plus proper Python escapes: backslash for quotation and backslash,\n",
    "    # percent for percent)\n",
    "    c = '--ryo \\\"STARTGENE\\\\n>{0}qi\\\\n{0}tas\\\\nENDGENE\\\\nSTARTCDS\\\\n>{0}qi\\\\n{0}tcs\\\\nENDCDS\\\\n \\\" '.format('%')\n",
    "    # gff\n",
    "    d = \"--showtargetgff \"\n",
    "    cline = a+b+c+d\n",
    "    \n",
    "    out, err = misc.execute_cline(cline)\n",
    "    \n",
    "    outhndl = open(str(chain)+'exo','wt')\n",
    "    outhndl.write(out)\n",
    "    outhndl.close()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        record = parse_a_single_record(list(iter_records(str(chain)+'exo'))[0])\n",
    "        os.remove(str(chain)+'exo')\n",
    "        return record\n",
    "    \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def dump_single_record_to_fasta_and_gff(record, ref_prot_seq_str):\n",
    "    \n",
    "    from warnings import warn\n",
    "    from Bio import SeqIO\n",
    "    from StringIO import StringIO\n",
    "    from distance import levenshtein\n",
    "    \n",
    "    seqrecord = SeqIO.read(StringIO(record['CDS']),'fasta')\n",
    "    seqrecord.description = ''\n",
    "    \n",
    "    gff = '#GlobalCounter%s\\n'%seqrecord.id+record['GFF']\n",
    "    \n",
    "    \n",
    "    # select frame\n",
    "    all_frames = [\n",
    "        \n",
    "        str(seqrecord.seq.translate()),\n",
    "        str(seqrecord.seq[1:].translate()),\n",
    "        str(seqrecord.seq[2:].translate())\n",
    "    ]\n",
    "    \n",
    "    dists = [levenshtein(ref_prot_seq_str, all_frames[0]),\n",
    "             levenshtein(ref_prot_seq_str, all_frames[1]),\n",
    "             levenshtein(ref_prot_seq_str, all_frames[2])]\n",
    "    \n",
    "    frame = dists.index(min(dists))\n",
    "    \n",
    "    prot_seq = all_frames[frame]\n",
    "    cds_seq = str(seqrecord.seq)[frame:]\n",
    "    \n",
    "    prot_has_stops = prot_seq.count('*') > 1\n",
    "    prot_has_stop = prot_seq.count('*') == 1\n",
    "    prot_endswith_stop = prot_seq.endswith('*')\n",
    "    early_stop = prot_has_stop and not prot_endswith_stop\n",
    "    bad_prot = any([prot_has_stops, early_stop])\n",
    "    \n",
    "    if prot_endswith_stop:\n",
    "        prot_seq = prot_seq[:-1]\n",
    "        \n",
    "    prot = \">%s\\n%s\\n\"%(seqrecord.id,prot_seq)\n",
    "    cds  = \">%s\\n%s\\n\"%(seqrecord.id,cds_seq)\n",
    "\n",
    "    return cds, prot, gff, bad_prot\n",
    "\n",
    "def single_sample_per_gene_exonerate(smpl, smpl2ref, chain = ''):\n",
    "    \n",
    "    from Bio import SeqIO\n",
    "    import os, sys, misc\n",
    "    from warnings import warn\n",
    "    \n",
    "    print smpl\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    smpl_genes_fpath = '%s_bwa/%s.nt.fasta'%(smpl,smpl)\n",
    "    ref_smpl = smpl2ref[smpl][0]\n",
    "    ref_prot_fpath = 'all_protein_ref_reviewed/%s_ref.aa.fasta'%ref_smpl\n",
    "    \n",
    "    genes = SeqIO.parse(smpl_genes_fpath,'fasta')\n",
    "    ref_prots = SeqIO.to_dict(SeqIO.parse(ref_prot_fpath,'fasta'))\n",
    "    \n",
    "    misc.makedir('cdss')\n",
    "    misc.makedir('gffs')\n",
    "    misc.makedir('proteins')\n",
    "    \n",
    "    misc.makedir('stopped_cdss')\n",
    "    misc.makedir('stopped_gffs')\n",
    "    misc.makedir('stopped_proteins')\n",
    "      \n",
    "    out_cdss = 'cdss/%s.cds.fasta'%smpl\n",
    "    gff_out =  'gffs/%s.gff'%smpl\n",
    "    prot_out = 'proteins/%s.aa.fasta'%smpl\n",
    "    \n",
    "    stopped_out_cdss = 'stopped_cdss/%s.cds.fasta'%smpl\n",
    "    stopped_gff_out =  'stopped_gffs/%s.gff'%smpl\n",
    "    stopped_prot_out = 'stopped_proteins/%s.aa.fasta'%smpl\n",
    "    \n",
    "    out_cdss = open(out_cdss,'wt')\n",
    "    gff_out = open(gff_out,'wt')\n",
    "    prot_out = open(prot_out,'wt')\n",
    "    \n",
    "    stopped_out_cdss = open(stopped_out_cdss,'wt')\n",
    "    stopped_gff_out = open(stopped_gff_out,'wt')\n",
    "    stopped_prot_out = open(stopped_prot_out,'wt')\n",
    "    \n",
    "    for gener in genes:\n",
    "        protr = ref_prots[gener.id]\n",
    "        \n",
    "        with open('%s_temp.gene'%smpl,'wt') as hndl:\n",
    "            hndl.write(gener.format('fasta'))\n",
    "        \n",
    "        with open('%s_temp.prot'%smpl,'wt') as hndl:\n",
    "            hndl.write(protr.format('fasta'))\n",
    "            \n",
    "        record = single_gene_exonerate('%s_temp.prot'%smpl,\n",
    "                                       '%s_temp.gene'%smpl,\n",
    "                                       chain = chain)\n",
    "        \n",
    "        if not record:\n",
    "            #print 0\n",
    "            sys.stdout.flush()\n",
    "            continue\n",
    "        \n",
    "        c, p, g, bad_prot = dump_single_record_to_fasta_and_gff(record, str(protr.seq))\n",
    "        \n",
    "        if all([c, p, g]):\n",
    "            if not bad_prot:\n",
    "                out_cdss.write(c)\n",
    "                prot_out.write(p)\n",
    "                gff_out.write(g)\n",
    "            else:\n",
    "                stopped_out_cdss.write(c)\n",
    "                stopped_prot_out.write(p)\n",
    "                stopped_gff_out.write(g)\n",
    "        else:\n",
    "            warn(\"sample %s gene %s had no output\"%(smpl,gener.id))\n",
    "        os.remove('%s_temp.prot'%smpl)\n",
    "        os.remove('%s_temp.gene'%smpl)\n",
    "    \n",
    "    prot_out.close()\n",
    "    gff_out.close()\n",
    "    out_cdss.close()\n",
    "    \n",
    "    stopped_prot_out.close()\n",
    "    stopped_gff_out.close()\n",
    "    stopped_out_cdss.close()\n",
    "    \n",
    "    sys.stderr.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for smpl in smpl2ref:\n",
    "    single_sample_per_gene_exonerate(smpl, smpl2ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import misc\n",
    "\n",
    "misc.makedir('all_gffs')\n",
    "\n",
    "cline = \"cat gffs/{0}.gff \"\n",
    "cline += \"stopped_gffs/{0}.gff > \"\n",
    "cline += \"all_gffs/{0}.gff\"\n",
    "\n",
    "for smpl in smpl2ref:\n",
    "    \n",
    "    misc.execute_cline(cline.format(smpl))\n",
    "\n",
    "import misc\n",
    "\n",
    "misc.makedir('all_proteins')\n",
    "\n",
    "cline = \"cat proteins/{0}.aa.fasta \"\n",
    "cline += \"stopped_proteins/{0}.aa.fasta > \"\n",
    "cline += \"all_proteins/{0}.aa.fasta\"\n",
    "\n",
    "for smpl in smpl2ref:\n",
    "    \n",
    "    misc.execute_cline(cline.format(smpl))\n",
    "    \n",
    "import misc\n",
    "\n",
    "misc.makedir('all_cdss')\n",
    "\n",
    "cline = \"cat cdss/{0}.cds.fasta \"\n",
    "cline += \"stopped_cdss/{0}.cds.fasta > \"\n",
    "cline += \"all_cdss/{0}.cds.fasta\"\n",
    "\n",
    "for smpl in smpl2ref:\n",
    "    \n",
    "    misc.execute_cline(cline.format(smpl))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
